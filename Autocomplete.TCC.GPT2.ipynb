{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating suggestions for writing source code in C# language based on NLP.\n",
    "\n",
    "\n",
    "## GPT-2 approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This notebook was created and adapted for the work of generating suggestions using some ideas and codes as reference the notebook of the author \"Mangeshkar, Saurav\" available at: \n",
    "https://www.kaggle.com/sauravmaheshkar/auto-completion-using-n-gram-models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import ntpath   \n",
    "from chardet import detect\n",
    "import nltk\n",
    "import re\n",
    "import h5py\n",
    "import numpy as np\n",
    "from toolz import unique\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from tokenizers.models import BPE\n",
    "from tokenizers import Tokenizer\n",
    "from tokenizers.decoders import ByteLevel as ByteLevelDecoder\n",
    "from tokenizers.normalizers import NFKC, Sequence\n",
    "from tokenizers.pre_tokenizers import ByteLevel\n",
    "from tokenizers.trainers import BpeTrainer\n",
    "from pathlib import Path\n",
    "import codecs\n",
    "import tensorflow as tf\n",
    "from transformers import GPT2Config, TFGPT2LMHeadModel, GPT2Tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BPE_token(object):\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.tokenizer = Tokenizer(BPE())\n",
    "        self.tokenizer.pre_tokenizer = ByteLevel()\n",
    "        self.tokenizer.normalizer = Sequence([\n",
    "            NFKC()\n",
    "        ])\n",
    "        self.tokenizer.decoder = ByteLevelDecoder()\n",
    "        \n",
    "    def bpe_train(self, paths):\n",
    "        trainer = BpeTrainer(show_progress=True, \n",
    "                             inital_alphabet=ByteLevel.alphabet(), \n",
    "                             special_tokens=[\"<s>\",\n",
    "                                             \"<pad>\",\n",
    "                                             \"</s>\",\n",
    "                                             \"<unk>\",\n",
    "                                             \"<mask>\"\n",
    "                                            ])\n",
    "        self.tokenizer.train(paths, trainer)\n",
    "\n",
    "    def save_tokenizer(self, location, prefix=None):\n",
    "        if not os.path.exists(location):\n",
    "            os.makedirs(location)\n",
    "        self.tokenizer.model.save(location, prefix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generic functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_list_to_data_file(data, file_name):\n",
    "    \"\"\"\n",
    "    Description: Function to export data into data file.\n",
    "    :param data: Data to export,\n",
    "    :param file_name: file name to export.\n",
    "    :return: void.\n",
    "    \"\"\"\n",
    "\n",
    "    with open(file_name, 'wb') as filehandle:\n",
    "        pickle.dump(data, filehandle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_from_data_file(file_name):\n",
    "    \"\"\"\n",
    "    Description: Function to load data from file.\n",
    "    :param file_name: file name to load data from.\n",
    "    :return - Type(list): Data list.\n",
    "    \"\"\"\n",
    "    \n",
    "    data = []\n",
    "\n",
    "    with open(file_name, 'rb') as filehandle:\n",
    "        data = pickle.load(filehandle)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_info(title, message = None, new_line = False):\n",
    "    \"\"\"\n",
    "    Description: Function to print info on screen\n",
    "    :param title: Message title,\n",
    "    :param message: Message to print,\n",
    "    :param new_line: Indicates whether the first message will start with a line break or not.\n",
    "    \n",
    "    :return: void.\n",
    "    \"\"\"\n",
    "    \n",
    "    if new_line:\n",
    "        print('\\n')\n",
    "    \n",
    "    print(\"####################################\")\n",
    "    print(title)\n",
    "    print(\"####################################\")\n",
    "    \n",
    "    if message:\n",
    "        print(\"%s\\n\" % (message))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sequence_of_numbers_from_string(str):\n",
    "    \"\"\"\n",
    "    Description: Function to extract all the sequence of numbers from the given string.\n",
    "    :param str: String to extract sequence of numbers.\n",
    "    \n",
    "    :return - Type(Array): Array with sequence of numbers.\n",
    "    \"\"\"\n",
    "    \n",
    "    array_numbers = re.findall(r'[0-9]+', str)\n",
    "    \n",
    "    return array_numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_sequence_of_numbers_for_mask(str_to_replace, \n",
    "                                         array_sequence_numbers_to_search, \n",
    "                                         mask_to_replace):\n",
    "    \"\"\"\n",
    "    Description: Function to replace sequence of numbers for specific mask.\n",
    "    :param str_to_replace: String to replace sequence of numbers,\n",
    "    :param array_sequence_numbers_to_search: Sequence numbers to search for,\n",
    "    :param mask_to_replace: Mask to replace each sequence.\n",
    "    \n",
    "    :return - Type(String): String with sequence of numbers replaced by mask.\n",
    "    \"\"\"\n",
    "    \n",
    "    for number_sequence in array_sequence_numbers_to_search:\n",
    "        str_to_replace = re.sub(str(number_sequence), mask_to_replace, str_to_replace, 1)\n",
    "\n",
    "    return str_to_replace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_encoding_type(file):\n",
    "    \"\"\"\n",
    "    Description: Function to retrieve enconding type of file.\n",
    "    :param file: File to get enconding.\n",
    "    \n",
    "    :return - Type(String): String with enconding type of file.\n",
    "    \"\"\"\n",
    "        \n",
    "    with open(file, 'rb') as f:\n",
    "        rawdata = f.read()\n",
    "    return detect(rawdata)['encoding']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_enconding(source_file, enconding):\n",
    "    \"\"\"\n",
    "    Description: Function to change enconding of file.\n",
    "    :param source_file: File to change enconding,\n",
    "    :param enconding: Enconding to replace in source_file.\n",
    "    \n",
    "    :return: void.\n",
    "    \"\"\"\n",
    "    \n",
    "    from_codec = get_encoding_type(source_file)\n",
    "    \n",
    "    try: \n",
    "        target_file = source_file.replace(ntpath.basename(source_file), \n",
    "                                      \"123%s\" % (ntpath.basename(source_file))) \n",
    "        \n",
    "        with open(source_file, \n",
    "                  'r', \n",
    "                  encoding=from_codec) as f, open(target_file, \n",
    "                                                  'w', \n",
    "                                                  encoding=enconding) as e:\n",
    "                text = f.read()\n",
    "                e.write(text)\n",
    "                f.close()\n",
    "\n",
    "        os.remove(source_file) \n",
    "        os.rename(target_file, source_file) \n",
    "        \n",
    "    except UnicodeDecodeError:\n",
    "        print(\"Decode error for file: '%s'\" % (source_file))\n",
    "    except UnicodeEncodeError:\n",
    "        print(\"Encode error for file: '%s'\" % (source_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_utf8_encode(file_name):\n",
    "    try:\n",
    "        content = codecs.open(file_name, encoding=\"utf-8\", errors=\"strict\").readlines()\n",
    "\n",
    "        if content is not None:\n",
    "            return True\n",
    "    except UnicodeDecodeError:\n",
    "        return False\n",
    "\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_list(list_to_flatten):\n",
    "    \"\"\"\n",
    "    Description: Function to flatten the given list.\n",
    "    :param list_to_flatten: List to flatten.\n",
    "    \n",
    "    :returns - Type(List): Flat list.\n",
    "    \"\"\"   \n",
    "    \n",
    "    return [f for child_list in list_to_flatten for f in child_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_duplicate_items_from_list(list_to_remove_duplicates):\n",
    "    \"\"\"\n",
    "    Description: Function to remove duplicate itens from given list.\n",
    "    :param list_to_remove_duplicates: List to remove duplicates.\n",
    "    \n",
    "    :returns - Type(List): List without duplicates.\n",
    "    \"\"\"  \n",
    "    \n",
    "    return list(map(list, unique(map(tuple, list_to_remove_duplicates))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read C# repository functions.\n",
    "\n",
    "#### Filter C# class files from root repository downladed from: https://github.com/dotnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_c_sharp_complete_file_names_for_each_class(root_directory):\n",
    "    \"\"\"\n",
    "    Description: Function to get all complete name of files with extension \".cs\" (C# class).\n",
    "    :param root_directory: Root directory of files.\n",
    "    \n",
    "    :return - Type(List): List with all file names of C# repository.\n",
    "    \"\"\"\n",
    "    \n",
    "    C_SHARP_CLASS_FILE_EXTENSION = \".cs\"\n",
    "    \n",
    "    complete_name_of_files = []\n",
    "\n",
    "    for root, dirs, files in os.walk(root_directory):\n",
    "        for file in files:\n",
    "            if file.endswith(C_SHARP_CLASS_FILE_EXTENSION):\n",
    "                complete_name_of_files.append(os.path.join(root, file))\n",
    "    \n",
    "    return complete_name_of_files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-processing functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_code_to_tokens(source_code):\n",
    "    \"\"\"\n",
    "    Description: Function to make pre-processing in source code and tokenize words.\n",
    "    :param source_code: Source code to pre-processing.\n",
    "    \n",
    "    :returns - Type(List): List of tokens.\n",
    "    \"\"\"\n",
    "    \n",
    "    MASK_NUMBERS = \"|mask_number|\"\n",
    "    \n",
    "    code_sentences = source_code.split('\\n')\n",
    "    \n",
    "    code_sentences = [c.strip() for c in code_sentences]\n",
    "    \n",
    "    code_sentences = [c for c in code_sentences if len(c) > 0]\n",
    "    \n",
    "    tokens = []\n",
    "    \n",
    "    for piece_of_code  in code_sentences:\n",
    "        token = nltk.word_tokenize(piece_of_code)\n",
    "\n",
    "        for i in range(len(token)):\n",
    "            token[i] = replace_sequence_of_numbers_for_mask(\n",
    "                            token[i],\n",
    "                            get_sequence_of_numbers_from_string(token[i]),\n",
    "                            MASK_NUMBERS)\n",
    "            \n",
    "        tokens.append(token)\n",
    "        \n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_all_files(complete_file_names, path_to_save_tokens):\n",
    "    \"\"\"\n",
    "    Description: Function to tokenize all files and save into specific folder.\n",
    "    :param complete_file_names: All C# files list (Name of each file),\n",
    "    :param path_to_save_tokens: Path to save generated tokens.\n",
    "    \n",
    "    :returns - Void.\n",
    "    \"\"\"\n",
    "    \n",
    "    tokenizer = BPE_token()\n",
    "\n",
    "    tokenizer.bpe_train([c for c in complete_file_names if check_utf8_encode(c) == True])\n",
    "\n",
    "    tokenizer.save_tokenizer(path_to_save_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GPT-2 Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_gpt2_model(tokens_path):\n",
    "    \n",
    "    # loading tokenizer from the saved model path\n",
    "    tokenizer = GPT2Tokenizer.from_pretrained(tokens_path)\n",
    "    tokenizer.add_special_tokens({\n",
    "      \"eos_token\": \"</s>\",\n",
    "      \"bos_token\": \"<s>\",\n",
    "      \"unk_token\": \"<unk>\",\n",
    "      \"pad_token\": \"<pad>\",\n",
    "      \"mask_token\": \"<mask>\"\n",
    "    })\n",
    "\n",
    "    # creating the configurations from which the model can be made\n",
    "    config = GPT2Config(\n",
    "      vocab_size=tokenizer.vocab_size,\n",
    "      bos_token_id=tokenizer.bos_token_id,\n",
    "      eos_token_id=tokenizer.eos_token_id\n",
    "    )\n",
    "\n",
    "    # creating the model\n",
    "    model = TFGPT2LMHeadModel(config)\n",
    "    \n",
    "    return (model, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_string_list_tokens(complete_file_names, tokenizer):\n",
    "    \n",
    "    single_string = ''\n",
    "    \n",
    "    for filename in complete_file_names:\n",
    "        with open(file_name, \"r\", encoding='utf-8') as f:\n",
    "            if check_utf8_encode(file_name) == True:\n",
    "                x = f.read()\n",
    "                single_string += x + tokenizer.eos_token\n",
    "\n",
    "    return tokenizer.encode(single_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tf_dataset_for_gpt2_training(tokens_list):\n",
    "    \n",
    "    examples = []\n",
    "    block_size = 100\n",
    "    BATCH_SIZE = 12\n",
    "    BUFFER_SIZE = 1000\n",
    "    \n",
    "    for i in range(0, len(tokens_list) - block_size + 1, block_size):\n",
    "        examples.append(tokens_list[i:i + block_size])\n",
    "    \n",
    "    inputs, labels = [], []\n",
    "    \n",
    "    for ex in examples:\n",
    "        inputs.append(ex[:-1])\n",
    "        labels.append(ex[1:])\n",
    "    \n",
    "    dataset = tf.data.Dataset.from_tensor_slices((inputs, labels))\n",
    "    dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)\n",
    "    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def config_model_to_gpt2(model):\n",
    "    \n",
    "    # defining our optimizer\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=3e-5, epsilon=1e-08, clipnorm=1.0)\n",
    "    \n",
    "    # definining our loss function\n",
    "    loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "    \n",
    "    # defining our metric which we want to observe\n",
    "    metric = tf.keras.metrics.SparseCategoricalAccuracy('accuracy')\n",
    "    \n",
    "    # compiling the model\n",
    "    model.compile(optimizer=optimizer, loss=[loss, *[None] * model.config.n_layer], metrics=[metric])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_to_gpt2(model, dataset, num_epoch):\n",
    "    \n",
    "    history = model.fit(dataset, epochs=num_epoch)\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_suggestions(previous_tokens, model, num_return_sequences, tokenizer):\n",
    "    \n",
    "    # encoding the input text\n",
    "    input_ids = tokenizer.encode(previous_tokens, return_tensors='tf')\n",
    "    # getting out output\n",
    "    beam_output = model.generate(\n",
    "      input_ids,\n",
    "      max_length = 50,\n",
    "      num_beams = 5,\n",
    "      temperature = 0.7,\n",
    "      no_repeat_ngram_size = 2,\n",
    "      num_return_sequences = num_return_sequences\n",
    "    )\n",
    "    \n",
    "    return tokenizer.decode(beam_output[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_5_combinations_top_most(n_grams_list):\n",
    "    \"\"\"\n",
    "    Description: Function to display 5 words combinations that appeared the most in each n-gram for param 'n_grams_list'.\n",
    "    :param n_grams_list: n-gram(s) list to show.\n",
    "    \n",
    "    :return: void.\n",
    "    \"\"\"\n",
    "\n",
    "    for i in range(0, len(n_gram_counts_list)):\n",
    "        n_grams_5_appeared_most = sorted(n_gram_counts_list[i].items(), key=lambda x: x[1], reverse=True)[:5]\n",
    "        print_info(\"%s-gram(s):\" % (i + 1))\n",
    "        data_for_dataframe = []\n",
    "\n",
    "        for words_and_counts in n_grams_5_appeared_most:\n",
    "            words_together_key = ''.join(words_and_counts[0])\n",
    "            count_words_value = words_and_counts[1]\n",
    "\n",
    "            each_line_dataframe = [words_together_key, count_words_value]\n",
    "\n",
    "            data_for_dataframe.append(each_line_dataframe)\n",
    "\n",
    "        df = pd.DataFrame(data_for_dataframe, columns = ['Words', 'Count'])\n",
    "        display(df)\n",
    "        print(\" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main flow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####################################\n",
      "First 10 files:\n",
      "####################################\n",
      "AssemblyResolution.cs\n",
      "AssemblyResolver.cs\n",
      "BuildTask.cs\n",
      "BuildTask.Desktop.cs\n",
      "DisposeAction.cs\n",
      "EnumerableExtensions.cs\n",
      "EnumExtensions.cs\n",
      "ArgumentEscaper.cs\n",
      "Command.cs\n",
      "CommandFactory.cs\n",
      "\n",
      "\n",
      "####################################\n",
      "Number of files for N-grams:\n",
      "####################################\n",
      "201706 files.\n"
     ]
    }
   ],
   "source": [
    "# Define constants.\n",
    "ROOT_DIRECTORY = \"D:\\DsTCC\"\n",
    "\n",
    "# Get all file names.\n",
    "complete_file_names = get_all_c_sharp_complete_file_names_for_each_class(ROOT_DIRECTORY)\n",
    "\n",
    "# Print first 10 files.\n",
    "print_info(\"First 10 files:\")\n",
    "\n",
    "for file_name in complete_file_names[:10]:\n",
    "    print(ntpath.basename(file_name))\n",
    "\n",
    "# Print total number of files.\n",
    "print_info(\"Number of files for N-grams:\", new_line=True)\n",
    "print(\"%s files.\" % (len(complete_file_names)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tokenize all files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "DIRECTORY_TO_SAVE_GENERATED_TOKENS = 'GPT2_Generated_Tokens'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = tokenize_all_files(complete_file_names, DIRECTORY_TO_SAVE_GENERATED_TOKENS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create GPT-2 model and vocabulary for tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "file GPT2_Generated_Tokens\\config.json not found\n"
     ]
    }
   ],
   "source": [
    "(model, tokenizer) = create_gpt2_model(DIRECTORY_TO_SAVE_GENERATED_TOKENS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create tokens list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'print_into' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-95-e6dada38a3ec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mtokens_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_string_list_tokens\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcomplete_file_names\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mprint_into\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"First 50 tokens from list:\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtokens_list\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'print_into' is not defined"
     ]
    }
   ],
   "source": [
    "tokens_list = create_string_list_tokens(complete_file_names, tokenizer)\n",
    "\n",
    "print_into(\"First 50 tokens from list:\")\n",
    "\n",
    "for token in tokens_list[:50]:\n",
    "    print(\"Position in vocabulary: %s\" % (token))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_list = load_from_data_file('tokens_list.data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####################################\n",
      "First 50 tokens from list:\n",
      "####################################\n",
      "Position in vocabulary: 237\n",
      "Position in vocabulary: 1257\n",
      "Position in vocabulary: 417\n",
      "Position in vocabulary: 324\n",
      "Position in vocabulary: 636\n",
      "Position in vocabulary: 739\n",
      "Position in vocabulary: 912\n",
      "Position in vocabulary: 866\n",
      "Position in vocabulary: 1136\n",
      "Position in vocabulary: 743\n",
      "Position in vocabulary: 1034\n",
      "Position in vocabulary: 1371\n",
      "Position in vocabulary: 18\n",
      "Position in vocabulary: 176\n",
      "Position in vocabulary: 237\n",
      "Position in vocabulary: 846\n",
      "Position in vocabulary: 636\n",
      "Position in vocabulary: 739\n",
      "Position in vocabulary: 912\n",
      "Position in vocabulary: 1370\n",
      "Position in vocabulary: 465\n",
      "Position in vocabulary: 804\n",
      "Position in vocabulary: 417\n",
      "Position in vocabulary: 1260\n",
      "Position in vocabulary: 866\n",
      "Position in vocabulary: 324\n",
      "Position in vocabulary: 1262\n",
      "Position in vocabulary: 1160\n",
      "Position in vocabulary: 18\n",
      "Position in vocabulary: 176\n",
      "Position in vocabulary: 176\n",
      "Position in vocabulary: 2498\n",
      "Position in vocabulary: 354\n",
      "Position in vocabulary: 31\n",
      "Position in vocabulary: 176\n",
      "Position in vocabulary: 2498\n",
      "Position in vocabulary: 354\n",
      "Position in vocabulary: 18\n",
      "Position in vocabulary: 947\n",
      "Position in vocabulary: 18\n",
      "Position in vocabulary: 962\n",
      "Position in vocabulary: 31\n",
      "Position in vocabulary: 176\n",
      "Position in vocabulary: 2498\n",
      "Position in vocabulary: 354\n",
      "Position in vocabulary: 18\n",
      "Position in vocabulary: 1490\n",
      "Position in vocabulary: 31\n",
      "Position in vocabulary: 176\n",
      "Position in vocabulary: 2498\n"
     ]
    }
   ],
   "source": [
    "print_info(\"First 50 tokens from list:\")\n",
    "\n",
    "for token in tokens_list[:50]:\n",
    "    print(\"Position in vocabulary: %s\" % (token))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_list_to_data_file(tokens_list, 'tokens_list.data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create tensor flow dataset for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = create_tf_dataset_for_gpt2_training(tokens_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.7.0\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Configure model and compile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = config_model_to_gpt2(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "    11/118166 [..............................] - ETA: 209:15:11 - loss: 8.8360 - logits_loss: 8.8360 - logits_accuracy: 0.1139 - past_key_values_1_accuracy: 0.0024 - past_key_values_2_accuracy: 0.0023 - past_key_values_3_accuracy: 0.0019 - past_key_values_4_accuracy: 0.0015 - past_key_values_5_accuracy: 0.0015 - past_key_values_6_accuracy: 0.0023 - past_key_values_7_accuracy: 0.0022 - past_key_values_8_accuracy: 0.0018 - past_key_values_9_accuracy: 0.0011 - past_key_values_10_accuracy: 0.0015 - past_key_values_11_accuracy: 0.0026 - past_key_values_12_accuracy: 0.0019"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-35-44f6fa0f8cd3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mNUM_EPOCH\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_model_to_gpt2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mNUM_EPOCH\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-33-5c870f3923ca>\u001b[0m in \u001b[0;36mtrain_model_to_gpt2\u001b[1;34m(model, dataset, num_epoch)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mtrain_model_to_gpt2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_epoch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnum_epoch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mhistory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1214\u001b[0m                 _r=1):\n\u001b[0;32m   1215\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1216\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1217\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1218\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    151\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    908\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    909\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 910\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    911\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    912\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    940\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    941\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 942\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    943\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    944\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3128\u001b[0m       (graph_function,\n\u001b[0;32m   3129\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 3130\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   3131\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m   3132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1957\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1958\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1959\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1960\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1961\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    596\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    597\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 598\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    599\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    600\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     56\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 58\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     59\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     60\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "NUM_EPOCH = 10\n",
    "history = train_model_to_gpt2(model, dataset, NUM_EPOCH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get suggestions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "previous_tokens = 'public'\n",
    "num_return_sequences = 5\n",
    "suggestion = get_suggestions(previous_tokens, model, num_return_sequences, tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Export tokens to backup file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_list_to_data_file(tokens, 'tokens_bkp.data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load tokens from backup file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = load_from_data_file('tokens_bkp.data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####################################\n",
      "First 50 tokens:\n",
      "####################################\n",
      "['//', 'Licensed', 'to', 'the', '.NET', 'Foundation', 'under', 'one', 'or', 'more', 'agreements', '.']\n",
      "['//', 'The', '.NET', 'Foundation', 'licenses', 'this', 'file', 'to', 'you', 'under', 'the', 'MIT', 'license', '.']\n",
      "['#', 'if', 'NET|mask_number|']\n",
      "['using', 'System', ';']\n",
      "['using', 'System.Collections.Generic', ';']\n",
      "['using', 'System.IO', ';']\n",
      "['using', 'System.Reflection', ';']\n",
      "['using', 'Microsoft.Build.Framework', ';']\n",
      "['using', 'Microsoft.Build.Utilities', ';']\n",
      "['namespace', 'Microsoft.DotNet']\n",
      "['{']\n",
      "['internal', 'static', 'class', 'AssemblyResolution']\n",
      "['{']\n",
      "['internal', 'static', 'TaskLoggingHelper', 'Log', ';']\n",
      "['public', 'static', 'void', 'Initialize', '(', ')']\n",
      "['{']\n",
      "['AppDomain.CurrentDomain.AssemblyResolve', '+=', 'AssemblyResolve', ';']\n",
      "['}']\n",
      "['private', 'static', 'Assembly', 'AssemblyResolve', '(', 'object', 'sender', ',', 'ResolveEventArgs', 'args', ')']\n",
      "['{']\n",
      "['var', 'name', '=', 'new', 'AssemblyName', '(', 'args.Name', ')', ';']\n",
      "['if', '(', '!', 'name.Name.Equals', '(', '``', 'System.Collections.Immutable', \"''\", ',', 'StringComparison.OrdinalIgnoreCase', ')', ')']\n",
      "['{']\n",
      "['return', 'null', ';']\n",
      "['}']\n",
      "['var', 'fullPath', '=', 'Path.Combine', '(', 'AppDomain.CurrentDomain.BaseDirectory', ',', '``', 'System.Collections.Immutable.dll', \"''\", ')', ';']\n",
      "['Assembly', 'sci', ';']\n",
      "['try']\n",
      "['{']\n",
      "['sci', '=', 'Assembly.LoadFile', '(', 'fullPath', ')', ';']\n",
      "['}']\n",
      "['catch', '(', 'Exception', 'e', ')']\n",
      "['{']\n",
      "['Log', '?', '.LogWarning', '(', '$', \"''\", 'AssemblyResolve', ':', 'exception', 'while', 'loading', \"'\", '{', 'fullPath', '}', \"'\", ':', '{', 'e.Message', '}', \"''\", ')', ';']\n",
      "['return', 'null', ';']\n",
      "['}']\n",
      "['if', '(', 'name.Version', '<', '=', 'sci.GetName', '(', ')', '.Version', ')']\n",
      "['{']\n",
      "['Log', '?', '.LogMessage', '(', 'MessageImportance.Low', ',', '$', \"''\", 'AssemblyResolve', ':', 'loaded', \"'\", '{', 'fullPath', '}', \"'\", 'to', '{', 'AppDomain.CurrentDomain.FriendlyName', '}', \"''\", ')', ';']\n",
      "['return', 'sci', ';']\n",
      "['}']\n",
      "['return', 'null', ';']\n",
      "['}']\n",
      "['}']\n",
      "['}']\n",
      "['#', 'endif']\n",
      "['//', 'Licensed', 'to', 'the', '.NET', 'Foundation', 'under', 'one', 'or', 'more', 'agreements', '.']\n",
      "['//', 'The', '.NET', 'Foundation', 'licenses', 'this', 'file', 'to', 'you', 'under', 'the', 'MIT', 'license', '.']\n",
      "['using', 'System', ';']\n",
      "['using', 'System.Diagnostics', ';']\n"
     ]
    }
   ],
   "source": [
    "print_info(\"First 50 tokens:\")\n",
    "for token in flatten_list(tokens)[:50]:\n",
    "    print(token) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Calling GPT2Tokenizer.from_pretrained() with the path to a single file or url is not supported for this tokenizer. Use a model identifier or the path to a directory instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-55b924009318>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# loading tokenizer from the saved model path\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mtokenizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGPT2Tokenizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'D:/Organizado/Acadêmicos/Usp/Pós Graduação/Monografia/Programas/Python/TCC.RenanMartins.Pece.IA.GPT2/tokens_bkp.data'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m tokenizer.add_special_tokens({\n\u001b[0;32m      7\u001b[0m   \u001b[1;34m\"eos_token\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m\"</s>\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\transformers\\tokenization_utils_base.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, *init_inputs, **kwargs)\u001b[0m\n\u001b[0;32m   1636\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misfile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mis_remote_url\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1637\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvocab_files_names\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1638\u001b[1;33m                 raise ValueError(\n\u001b[0m\u001b[0;32m   1639\u001b[0m                     \u001b[1;34mf\"Calling {cls.__name__}.from_pretrained() with the path to a single file or url is not \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1640\u001b[0m                     \u001b[1;34m\"supported for this tokenizer. Use a model identifier or the path to a directory instead.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Calling GPT2Tokenizer.from_pretrained() with the path to a single file or url is not supported for this tokenizer. Use a model identifier or the path to a directory instead."
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from transformers import GPT2Config, TFGPT2LMHeadModel, GPT2Tokenizer\n",
    "\n",
    "# loading tokenizer from the saved model path\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('D:/Organizado/Acadêmicos/Usp/Pós Graduação/Monografia/Programas/Python/TCC.RenanMartins.Pece.IA.GPT2/tokens_bkp.data')\n",
    "tokenizer.add_special_tokens({\n",
    "  \"eos_token\": \"</s>\",\n",
    "  \"bos_token\": \"<s>\",\n",
    "  \"unk_token\": \"<unk>\",\n",
    "  \"pad_token\": \"<pad>\",\n",
    "  \"mask_token\": \"<mask>\"\n",
    "})\n",
    "\n",
    "# creating the configurations from which the model can be made\n",
    "config = GPT2Config(\n",
    "  vocab_size=tokenizer.vocab_size,\n",
    "  bos_token_id=tokenizer.bos_token_id,\n",
    "  eos_token_id=tokenizer.eos_token_id\n",
    ")\n",
    "\n",
    "# creating the model\n",
    "model = TFGPT2LMHeadModel(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get tokens and vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_freq = 3\n",
    "new_data_tokens, vocabulary = processing_vocabulary_and_unknown(tokens, min_freq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get n-grams count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "QUANTITY_NGRAMS_TO_GENERATE = 5\n",
    "\n",
    "n_gram_counts_list = []\n",
    "for n in range(1, QUANTITY_NGRAMS_TO_GENERATE + 1):\n",
    "    n_model_counts = count_n_grams(new_data_tokens, n)\n",
    "    n_gram_counts_list.append(n_model_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Display 5 words combinations that appeared the most in each n-gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####################################\n",
      "1-gram(s):\n",
      "####################################\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Words</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>)</td>\n",
       "      <td>23203367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(</td>\n",
       "      <td>23202300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>,</td>\n",
       "      <td>11792814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>;</td>\n",
       "      <td>10033382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>=</td>\n",
       "      <td>5635404</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Words     Count\n",
       "0     )  23203367\n",
       "1     (  23202300\n",
       "2     ,  11792814\n",
       "3     ;  10033382\n",
       "4     =   5635404"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "####################################\n",
      "2-gram(s):\n",
      "####################################\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Words</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>((</td>\n",
       "      <td>9146342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>);</td>\n",
       "      <td>5200301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>;}</td>\n",
       "      <td>2957248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>)+</td>\n",
       "      <td>2927367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>){</td>\n",
       "      <td>2854688</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Words    Count\n",
       "0    ((  9146342\n",
       "1    );  5200301\n",
       "2    ;}  2957248\n",
       "3    )+  2927367\n",
       "4    ){  2854688"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "####################################\n",
      "3-gram(s):\n",
      "####################################\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Words</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(((</td>\n",
       "      <td>8644068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>);}</td>\n",
       "      <td>1520228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[|mask_number|]</td>\n",
       "      <td>1325311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>,|mask_number|x|mask_number|,</td>\n",
       "      <td>1293989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>|mask_number|])</td>\n",
       "      <td>1059917</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Words    Count\n",
       "0                            (((  8644068\n",
       "1                            );}  1520228\n",
       "2                [|mask_number|]  1325311\n",
       "3  ,|mask_number|x|mask_number|,  1293989\n",
       "4                |mask_number|])  1059917"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "####################################\n",
      "4-gram(s):\n",
      "####################################\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Words</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>((((</td>\n",
       "      <td>8554307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[|mask_number|])</td>\n",
       "      <td>1042245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>|mask_number|x|mask_number|,|mask_number|x|mas...</td>\n",
       "      <td>1020632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>,|mask_number|x|mask_number|,|mask_number|x|ma...</td>\n",
       "      <td>1016741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>--------</td>\n",
       "      <td>901374</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Words    Count\n",
       "0                                               ((((  8554307\n",
       "1                                   [|mask_number|])  1042245\n",
       "2  |mask_number|x|mask_number|,|mask_number|x|mas...  1020632\n",
       "3  ,|mask_number|x|mask_number|,|mask_number|x|ma...  1016741\n",
       "4                                           --------   901374"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "####################################\n",
      "5-gram(s):\n",
      "####################################\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Words</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(((((</td>\n",
       "      <td>8489794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>,|mask_number|x|mask_number|,|mask_number|x|ma...</td>\n",
       "      <td>1014999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>----------</td>\n",
       "      <td>865768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>*****</td>\n",
       "      <td>863235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>|mask_number|x|mask_number|,|mask_number|x|mas...</td>\n",
       "      <td>832296</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Words    Count\n",
       "0                                              (((((  8489794\n",
       "1  ,|mask_number|x|mask_number|,|mask_number|x|ma...  1014999\n",
       "2                                         ----------   865768\n",
       "3                                              *****   863235\n",
       "4  |mask_number|x|mask_number|,|mask_number|x|mas...   832296"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n"
     ]
    }
   ],
   "source": [
    "display_5_combinations_top_most(n_gram_counts_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Export ngrams x counts list, new data tokens and vocabulary to backup file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_list_to_data_file(n_gram_counts_list, 'n_gram_counts_list.data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_list_to_data_file(new_data_tokens, 'new_data_tokens.data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_list_to_data_file(vocabulary, 'vocabulary.data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load ngrams x counts list, new data tokens and vocabulary from backup file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_gram_counts_list = load_from_data_file('n_gram_counts_list.data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data_tokens = load_from_data_file('new_data_tokens.data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary = load_from_data_file('vocabulary.data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get suggestions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ngram</th>\n",
       "      <th>previous_tokens</th>\n",
       "      <th>suggestions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>[public]</td>\n",
       "      <td>[[(static, 0.13878612711693716), (void, 0.1022...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>[public, static]</td>\n",
       "      <td>[[(void, 0.05360907345975815), (string, 0.0453...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>[public, static, void]</td>\n",
       "      <td>[[(&lt;unk&gt;, 0.02085204659309168), (Main, 0.00996...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>[public, static, void, &lt;unk&gt;]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>[public, static, void, Main]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>5</td>\n",
       "      <td>[public, int, &lt;unk&gt;, {]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>5</td>\n",
       "      <td>[public, int, &lt;unk&gt;, (]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>5</td>\n",
       "      <td>[public, int, &lt;unk&gt;, ;]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>5</td>\n",
       "      <td>[public, int, &lt;unk&gt;, =]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>5</td>\n",
       "      <td>[public, int, &lt;unk&gt;, &lt;]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>156 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     ngram                previous_tokens  \\\n",
       "0        2                       [public]   \n",
       "1        3               [public, static]   \n",
       "2        4         [public, static, void]   \n",
       "3        5  [public, static, void, <unk>]   \n",
       "4        5   [public, static, void, Main]   \n",
       "..     ...                            ...   \n",
       "151      5        [public, int, <unk>, {]   \n",
       "152      5        [public, int, <unk>, (]   \n",
       "153      5        [public, int, <unk>, ;]   \n",
       "154      5        [public, int, <unk>, =]   \n",
       "155      5        [public, int, <unk>, <]   \n",
       "\n",
       "                                           suggestions  \n",
       "0    [[(static, 0.13878612711693716), (void, 0.1022...  \n",
       "1    [[(void, 0.05360907345975815), (string, 0.0453...  \n",
       "2    [[(<unk>, 0.02085204659309168), (Main, 0.00996...  \n",
       "3                                                   []  \n",
       "4                                                   []  \n",
       "..                                                 ...  \n",
       "151                                                 []  \n",
       "152                                                 []  \n",
       "153                                                 []  \n",
       "154                                                 []  \n",
       "155                                                 []  \n",
       "\n",
       "[156 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "suggestions_for_all_grams = []\n",
    "previous_tokens = [\"public\"]\n",
    "\n",
    "get_suggestions_recursively(previous_tokens, \n",
    "                            n_gram_counts_list, \n",
    "                            vocabulary, \n",
    "                            suggestions_for_all_grams, \n",
    "                            QUANTITY_NGRAMS_TO_GENERATE)\n",
    "    \n",
    "df = pd.DataFrame(suggestions_for_all_grams, columns=['ngram', 'previous_tokens', 'suggestions'])\n",
    "\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Format each n-gram level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_words_and_probability(df):\n",
    "    \n",
    "    formated_results = []\n",
    "    \n",
    "    for index, row in df.iterrows():\n",
    "        \n",
    "        previous_tokens = ' '.join(row['previous_tokens'])\n",
    "        \n",
    "        if len(row['suggestions']) > 0:\n",
    "            for suggestion in row['suggestions'][0]:\n",
    "                formated_results.append((previous_tokens, previous_tokens + \" \" + suggestion[0], suggestion[1]))\n",
    "      \n",
    "    return formated_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ngram</th>\n",
       "      <th>previous_tokens</th>\n",
       "      <th>suggestions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>[public, static, void, &lt;unk&gt;]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>[public, static, void, Main]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>[public, static, void, foo|mask_number|]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5</td>\n",
       "      <td>[public, static, void, DynamicCSharpRunTest]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5</td>\n",
       "      <td>[public, static, void, Write]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>5</td>\n",
       "      <td>[public, int, &lt;unk&gt;, {]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>5</td>\n",
       "      <td>[public, int, &lt;unk&gt;, (]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>5</td>\n",
       "      <td>[public, int, &lt;unk&gt;, ;]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>5</td>\n",
       "      <td>[public, int, &lt;unk&gt;, =]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>5</td>\n",
       "      <td>[public, int, &lt;unk&gt;, &lt;]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>125 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     ngram                               previous_tokens suggestions\n",
       "3        5                 [public, static, void, <unk>]          []\n",
       "4        5                  [public, static, void, Main]          []\n",
       "5        5      [public, static, void, foo|mask_number|]          []\n",
       "6        5  [public, static, void, DynamicCSharpRunTest]          []\n",
       "7        5                 [public, static, void, Write]          []\n",
       "..     ...                                           ...         ...\n",
       "151      5                       [public, int, <unk>, {]          []\n",
       "152      5                       [public, int, <unk>, (]          []\n",
       "153      5                       [public, int, <unk>, ;]          []\n",
       "154      5                       [public, int, <unk>, =]          []\n",
       "155      5                       [public, int, <unk>, <]          []\n",
       "\n",
       "[125 rows x 3 columns]"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_formated = df.copy()\n",
    "df_ngrams = df_formated.query(\"ngram==5\")\n",
    "df_ngrams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### N-grams suggested"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####################################\n",
      "2-gram(s):\n",
      "####################################\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "</style><table id=\"T_18e14_\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >Previous_Tokens</th>        <th class=\"col_heading level0 col1\" >Suggestion</th>        <th class=\"col_heading level0 col2\" >Probability</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_18e14_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "                        <td id=\"T_18e14_row0_col0\" class=\"data row0 col0\" >public</td>\n",
       "                        <td id=\"T_18e14_row0_col1\" class=\"data row0 col1\" >public static</td>\n",
       "                        <td id=\"T_18e14_row0_col2\" class=\"data row0 col2\" >13.88%</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_18e14_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "                        <td id=\"T_18e14_row1_col0\" class=\"data row1 col0\" >public</td>\n",
       "                        <td id=\"T_18e14_row1_col1\" class=\"data row1 col1\" >public void</td>\n",
       "                        <td id=\"T_18e14_row1_col2\" class=\"data row1 col2\" >10.22%</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_18e14_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "                        <td id=\"T_18e14_row2_col0\" class=\"data row2 col0\" >public</td>\n",
       "                        <td id=\"T_18e14_row2_col1\" class=\"data row2 col1\" >public class</td>\n",
       "                        <td id=\"T_18e14_row2_col2\" class=\"data row2 col2\" >5.02%</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_18e14_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "                        <td id=\"T_18e14_row3_col0\" class=\"data row3 col0\" >public</td>\n",
       "                        <td id=\"T_18e14_row3_col1\" class=\"data row3 col1\" >public override</td>\n",
       "                        <td id=\"T_18e14_row3_col2\" class=\"data row3 col2\" >4.91%</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_18e14_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "                        <td id=\"T_18e14_row4_col0\" class=\"data row4 col0\" >public</td>\n",
       "                        <td id=\"T_18e14_row4_col1\" class=\"data row4 col1\" >public int</td>\n",
       "                        <td id=\"T_18e14_row4_col2\" class=\"data row4 col2\" >4.00%</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1d0a276edc0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "####################################\n",
      "3-gram(s):\n",
      "####################################\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "</style><table id=\"T_9c5b2_\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >Previous_Tokens</th>        <th class=\"col_heading level0 col1\" >Suggestion</th>        <th class=\"col_heading level0 col2\" >Probability</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_9c5b2_level0_row0\" class=\"row_heading level0 row0\" >5</th>\n",
       "                        <td id=\"T_9c5b2_row0_col0\" class=\"data row0 col0\" >public void</td>\n",
       "                        <td id=\"T_9c5b2_row0_col1\" class=\"data row0 col1\" >public void <unk></td>\n",
       "                        <td id=\"T_9c5b2_row0_col2\" class=\"data row0 col2\" >10.30%</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_9c5b2_level0_row1\" class=\"row_heading level0 row1\" >20</th>\n",
       "                        <td id=\"T_9c5b2_row1_col0\" class=\"data row1 col0\" >public int</td>\n",
       "                        <td id=\"T_9c5b2_row1_col1\" class=\"data row1 col1\" >public int m|mask_number|</td>\n",
       "                        <td id=\"T_9c5b2_row1_col2\" class=\"data row1 col2\" >5.61%</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_9c5b2_level0_row2\" class=\"row_heading level0 row2\" >0</th>\n",
       "                        <td id=\"T_9c5b2_row2_col0\" class=\"data row2 col0\" >public static</td>\n",
       "                        <td id=\"T_9c5b2_row2_col1\" class=\"data row2 col1\" >public static void</td>\n",
       "                        <td id=\"T_9c5b2_row2_col2\" class=\"data row2 col2\" >5.36%</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_9c5b2_level0_row3\" class=\"row_heading level0 row3\" >1</th>\n",
       "                        <td id=\"T_9c5b2_row3_col0\" class=\"data row3 col0\" >public static</td>\n",
       "                        <td id=\"T_9c5b2_row3_col1\" class=\"data row3 col1\" >public static string</td>\n",
       "                        <td id=\"T_9c5b2_row3_col2\" class=\"data row3 col2\" >4.53%</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_9c5b2_level0_row4\" class=\"row_heading level0 row4\" >10</th>\n",
       "                        <td id=\"T_9c5b2_row4_col0\" class=\"data row4 col0\" >public class</td>\n",
       "                        <td id=\"T_9c5b2_row4_col1\" class=\"data row4 col1\" >public class Class|mask_number|</td>\n",
       "                        <td id=\"T_9c5b2_row4_col2\" class=\"data row4 col2\" >4.42%</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1d0a6eb3e20>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "####################################\n",
      "4-gram(s):\n",
      "####################################\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "</style><table id=\"T_1aec9_\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >Previous_Tokens</th>        <th class=\"col_heading level0 col1\" >Suggestion</th>        <th class=\"col_heading level0 col2\" >Probability</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_1aec9_level0_row0\" class=\"row_heading level0 row0\" >25</th>\n",
       "                        <td id=\"T_1aec9_row0_col0\" class=\"data row0 col0\" >public void <unk></td>\n",
       "                        <td id=\"T_1aec9_row0_col1\" class=\"data row0 col1\" >public void <unk> (</td>\n",
       "                        <td id=\"T_1aec9_row0_col2\" class=\"data row0 col2\" >12.10%</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_1aec9_level0_row1\" class=\"row_heading level0 row1\" >100</th>\n",
       "                        <td id=\"T_1aec9_row1_col0\" class=\"data row1 col0\" >public int m|mask_number|</td>\n",
       "                        <td id=\"T_1aec9_row1_col1\" class=\"data row1 col1\" >public int m|mask_number| =</td>\n",
       "                        <td id=\"T_1aec9_row1_col2\" class=\"data row1 col2\" >5.98%</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_1aec9_level0_row2\" class=\"row_heading level0 row2\" >50</th>\n",
       "                        <td id=\"T_1aec9_row2_col0\" class=\"data row2 col0\" >public class Class|mask_number|</td>\n",
       "                        <td id=\"T_1aec9_row2_col1\" class=\"data row2 col1\" >public class Class|mask_number| {</td>\n",
       "                        <td id=\"T_1aec9_row2_col2\" class=\"data row2 col2\" >4.90%</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_1aec9_level0_row3\" class=\"row_heading level0 row3\" >5</th>\n",
       "                        <td id=\"T_1aec9_row3_col0\" class=\"data row3 col0\" >public static string</td>\n",
       "                        <td id=\"T_1aec9_row3_col1\" class=\"data row3 col1\" >public static string Property</td>\n",
       "                        <td id=\"T_1aec9_row3_col2\" class=\"data row3 col2\" >4.73%</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_1aec9_level0_row4\" class=\"row_heading level0 row4\" >0</th>\n",
       "                        <td id=\"T_1aec9_row4_col0\" class=\"data row4 col0\" >public static void</td>\n",
       "                        <td id=\"T_1aec9_row4_col1\" class=\"data row4 col1\" >public static void <unk></td>\n",
       "                        <td id=\"T_1aec9_row4_col2\" class=\"data row4 col2\" >2.09%</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1d09f41ea90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n"
     ]
    }
   ],
   "source": [
    "df_formated = df.copy()\n",
    "\n",
    "for i in range(2, QUANTITY_NGRAMS_TO_GENERATE):\n",
    "\n",
    "    print_info(\"%s-gram(s):\" % (i))\n",
    "    \n",
    "    df_ngrams = df_formated.query(\"ngram==%s\" % (i))\n",
    "    \n",
    "    formated_results = format_words_and_probability(df_ngrams)\n",
    "    \n",
    "    df_ngrams_formated = pd.DataFrame(formated_results, columns=['Previous_Tokens', 'Suggestion', 'Probability'])\n",
    "    \n",
    "    df_top_5 = df_ngrams_formated.sort_values(by='Probability',ascending=False).iloc[:5,:]\n",
    "    df_top_5 = df_top_5.style.format({'Probability': \"{:.2%}\"})\n",
    "    display(df_top_5)\n",
    "    \n",
    "    print(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
